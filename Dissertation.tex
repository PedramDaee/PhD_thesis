%% Select the dissertation mode on
%
% See the documentation for more information about the available class options 
% ('math', 'vertlayout', 'pdfa', ...)
% If you give option 'draft' or 'draft*', the draft mode is turned on
% NOTE if you want to generate abstracts for the publication platform, use
% the option 'abstracts'!
% The pdfa option is experimental, but give it a try -- your doc will be better archivable
%
\documentclass[dissertation,math,vertlayout,pdfa,colorlinks]{aaltoseries}

% Kludge to make sure we have utf8 input (check that this file is utf8!)
\makeatletter
\@ifpackageloaded{inputenc}{%
  \inputencoding{utf8}}{%
  \usepackage[utf8]{inputenc}}
\makeatother

% for live links. Takes the above option 'colorlinks' (use 'hidelinks' if you want them black for print).
\usepackage{hyperref} 

% Lipsum package generates quasi latin filler text
\usepackage{lipsum}
% Set the document languages used
\usepackage[english]{babel}
% more math symbols and environments if needed
\usepackage{amsmath,amssymb,amsthm} 
% after amsmath to restore bad page breaks in the middle of equations... only for those in the know
\interdisplaylinepenalty=2500 
% Adjust math line spacing
\renewcommand*{\arraystretch}{1.2} % for array/matrix environments
\setlength{\jot}{8pt} % for split environment

\usepackage{listings} % neat printing of source code
\usepackage[indentfirst=false,vskip=3mm]{quoting} % flexible quotes and quotations
% Enable the following to suppress page headers and numbers on 
% content-less left (even-numbered) pages. Fixes a bug in aaltoseries
\usepackage{emptypage}
\usepackage[nobiblatex]{xurl}


%Mathematical notations used 
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{bm}

\newcommand{\bw}{\bm{w}}
\newcommand{\bX}{\bm{X}}
\newcommand{\by}{\bm{y}}
\newcommand{\bD}{\mathcal{D}}
\newcommand{\bF}{\mathcal{F}}
\DeclareMathOperator{\eye}{\textbf{I}}

\DeclarePairedDelimiterX{\infdivx}[2]{[}{]}{%
	#1\;\delimsize\|\;#2%
}
\DeclareMathOperator{\KLt}{KL}
\newcommand{\KL}{\KLt\infdivx}
\DeclareMathOperator{\betapdf}{Beta}
\DeclareMathOperator{\bernoullipdf}{Bernoulli}
\DeclareMathOperator{\normalpdf}{N}
\DeclareMathOperator{\gammapdf}{Gamma}
\DeclareMathOperator{\new}{new}
\DeclareMathOperator{\old}{old}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\var}{var}
\newcommand{\tp}{^{\top}}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,fit,positioning,shapes.symbols,chains}

\usepackage{graphicx}
%%
%% There's a HUGE number of LaTeX packages. Whatever it is you need, search for a package first before rolling your own!
%%

% This is the way you may input and separately develop your individual chapters. Write, e.g., 
%
%	%\input{Ch1}
%	%\input{Ch2}
%	\input{Ch3}
%	%\input{Ch4}
%	%\input{Ch5}
%
% ...when editing only the third chapter. Compilation with pdflatex ('pdflatex dissertation') will then only output
% a thin dissertation containing only the third chapter, but properly formatted.
%
% You may leave of the .tex extension here...
%\input{dummymathcode/testmathcommand.tex}

% The author of the dissertation
\author{Pedram Daee}
% The title of the thesis
\title{Interactive user modelling for human-in-the-loop machine learning} % This is the title of our line of work as a group.

%Comments from meeting with Sami on 15.07.2019:
% "user modelling" may not be the best term as people may perceive it as a statitstic UM. But "probabilistic user modelling" in a good context may be OK.
%  We want to have User + probabilistic in the title.
% Alternatives for user could be human-in-the-loop or user interaction or HCI or modellign of the user or interactive user modelling
% an alternative title could be to directly mention what I did: knowledge elicitation or multi source feedback. Or use these as subtitles?


%Keywords: Interactive intent modelling, User modelling, Interactive knowledge elicitation, Active elicitation of knowledge, Sequential probabilistic inference, high dimensional prediction.
%0. Probabilistic user modelling methods for improving human-in-the-loop machine learning
%1.	Probabilistic User Modelling in Interactive Machine Learning for Prediction
%2.	Machine learning methods for user modelling for improved prediction.
%3.	Interactive user/expert modelling for improved prediction 
%4.	Machine Learning Methods for Improved Prediction through Probabilistic User Modelling
%5.	Improved Prediction through Interactive Probabilistic User Modelling
%6.	Probabilistic user modelling methods for improving human-in-the-loop machine learning.

%Other comments: I do not like knowledge elicitation since it seems like a term that may become obsolete through time

\begin{document}

%% The abstract of the dissertation in English
% Use this command!
%\draftabstract{\lipsum[1-2]}%
%\draftabstract[english]{\hspace{-2pt} My abstract in English}
% Let's add another one in Finnish
%\draftabstract[finnish]{\hspace{-2pt} En puhu suomea1

%}%


% And yet another one in Swedish
%\draftabstract[swedish]{\lipsum[7-9]}
%%---------------------

%% The abstract of the dissertation in English
% Use this command!
%\begin{abstract}\lipsum[1-3]\end{abstract}%
% Let's add another one in Finnish

\begin{abstract}[english]
	Ongoing title: \\
	\textbf{1. Probabilistic user modelling for improving human-in-the-loop machine learning}
	
	\noindent\textbf{2. Probabilistic user modelling methods for improving human-in-the-loop machine learning}
	
	\noindent\textbf{3. Interactive user modelling for human-in-the-loop machine learning} % NOTE: Interactive and in-the-loop are a bit redundant
	
	
	
	
	
%early comments from Sami: Drop half of the abstract and put it in the intro. Go into the gist and why it is different and what is done immediately. Sami thinks that the gist is “joint model of human and data through active learning, experimental design on a budget”. Add one sentence why it is a hard problem, then add another sentence that “and that is why we …..” to connect to your contribution. Sami thinks that intent modelling in IR is not prediction, but we model and solved it as a prediction problem. Maybe have “relevance of variables” as a keyword since this may be what I am doing. Regarding the title, keep the spirit but focus more. E.g., “human intent modelling for eliciting importance of variables” (knowledge elicitation?). Try to list 5 example titles and then have a meeting with Sami.
\end{abstract}

%1. What is the bigger picture?
%2. Dissertation purpose
%3. Research method
%4. Key results
%5. Practical Implications

%Typically 3 paragraphs: 1. the introduction of the challenge problem, 2. thesis, 3. contribution

 
\begin{abstract}%[finnish]
En puhu suomea.
\end{abstract}


% And yet another one in Swedish
%\begin{abstract}[swedish]\lipsum[7-9]\end{abstract}


%% Preface
% If you write this somewhere else than in Helsinki, use the optional location.
\begin{preface}[Espoo]
To fill.
%Maybe consider whom you should acknowledge. 
% at the very least, all the co-authors, group members who have worked in this or have acknowledge you in their theses, and the funding agencies (reknow, MindSee, WAI?)

\end{preface}

%% Table of contents of the dissertation
\clearpage
\tableofcontents

% To be defined before generating list of publications. Leave off if no acknowledgement
%\languagecheck{the Institute of Language Checks}

%% This is for article dissertations. Remove if you write a monograph dissertation.
% The actual publications are entered manually one by one as shown further down:
% use \addpublication, \addcontribution, \adderrata, and addpublicationpdf.
% The last adds the actual article, the other three enter related information
% that will be collected in lists -- like this one.
\listofpublications

%% Add lists of figures and tables as you usually do (\listoffigures, \listoftables)

%%%%%%%%%%%%%%%%%%%%%%% do I want to have the followings? 
%\listoffigures
%\listoftables

%\abbreviations
%\begin{description}
%\item[PDF] Probability Density Function
%\end{description}

%\symbols
%\begin{description}
%\item[$p(\theta \mid y)$] Conditional distribution
%\end{description}


%% The main matter, one can obviously use \input or \include
\chapter{Introduction}
%Comments from meeting with Sami on 15.07.2019:
% I need to tie to non-ML related works somewhere in the paper. This can include HCI related works or knowledge elicitation or multi agent? I need to either list them here and give a short descriotion or put them inside the next two chapters. In any case, I need to refer back to these in the Discussion section and mention how we improved the fields (and how we benefited from these).


Whether it is an everyday user searching for an application in her mobile phone or a doctor working with a cancer diagnostic system, humans and machines are increasingly interacting with each other \cite{amershi2014power}. The aim of this thesis is to improve this interaction by incorporating a probabilistic model of the human user in the system they are interacting with. In particular, the thesis considers the family of problems where the human and machine interact to solve a prediction problem. Such problems can include personalized search activity or medical prediction about the response of a cancer drug. An important common factor in these scenarios is that the number of labeled data (known as training data) that the machine can use to make predictions, is usually very few compared to the dimension of search space. This is known as the ``small $n$, large $p$'' problem ($n$ referring to the number of available labeled data and $p$ the size of the dimension) which results in ill-posed statistical learning since there are limits in how low in sample size statistical methods can go \cite{Donoho2009observed}. 

There are different ways to handle the limited labeled data challenge. The most direct solution is to provide more labeled data for the model. However, due to the high cost (e.g., experimenting the drug response on a new patient in drug response prediction task) or the nature of the data provider (e.g., reluctance of users to provide many feedbacks about their interest in personalized search systems), adding more training data data may not always be possible. An alternative direction is to restrict the model family to a simpler family of solutions (for example by assuming linearity and/or sparsity \cite{lasso2011}) to prevent the model from overfitting to the few available labeled data. A less explored direction for tackling the limited data challenge particularly in human-in-the-loop systems is to make prior assumptions about how user interaction with the system is generated and exploit this knowledge to extract more information from limited interaction. This approach is known as user modelling in human--computer interaction (see for example \cite{user_modelling_2001}) and it broadly studies ways to improve usability and usefulness of human--computer collaboration.

%\section{Motivation}

 
\section{Research questions and contributions}


This thesis investigates methods to tackle the limited user interaction challenge in interactive machine learning for prediction. The thesis focuses on scenarios where there is few labeled data available compared to the dimension of the problem, or when a human user is provider of the labeled data. The core idea of the thesis is to jointly model the human user, as a probabilistic user model, with the data as part of a unified probabilistic model and then perform sequential probabilistic inference on the joint model to design improved interaction.  The thesis focuses on the following research questions derived from the core idea mentioned above:\\

\noindent \textbf{RQ1 --} \textit{Can we exploit new sources of interaction as additional learning signals from human user to improve interactive intent modelling?}

Publications I and V contribute to this research question by proposing models to incorporate new types of user feedback to amend the limited feedback in exploratory information seeking tasks. The focused task is an article search scenario where a user needs to sequentially provide relevance feedback to suggested keywords in order to find the targeted article. This is modelled as a multi-armed bandit problem with the goal of finding the most relevant article with minimum interaction. In particular, Publication I couples user relevance feedback on both articles and keywords by assuming a shared underlying latent intent model connected through a probabilistic model of the relationship between keywords and articles. Thompson sampling on the posterior of the latent intent was then used to recommend new articles and keywords in each iteration. Publication V investigates the use of implicit relevance feedback from neurophysiology signals for effortless information seeking. The work contributes by demonstrating how to integrate this inherently noisy and implicit feedback source with scarce explicit interaction. A model for controlling the accuracy of the feedback given its nature (implicit or explicit) was introduced. Similar to Publication I, Thompson sampling was used to control the exploration and exploitation balance of the recommendations. Both publications were evaluated by user studies in realistic information seeking tasks. 


\noindent \textbf{RQ2 --} \textit{Can expert knowledge about high dimensional data models be elicited to improve the prediction performance?}

Publications II and III contribute to this research question. Publication II proposes a framework for user knowledge elicitation as a probabilistic inference process, where the user knowledge is sequentially queried to improve predictions on a ``small $n$, large $p$'' problem. In particular, sparse linear regression is considered as the data model with access to only few high-dimensional training data. It is assumed that there are experts who have knowledge about the relevance of the covariates, or of values of the regression coefficients and can provide this information to the data model if queried. The work contributes by an algorithm and computational approximation for fast and efficient interaction, which sequentially identifies the most informative queries to ask from the user. Publication III, builds on Publication II by adding user knowledge about direction of relevance of covariates and applying the method in important application of precision medicine to predict the effects of different treatments using high-dimensional genomic measurements. Both publications were evaluated by extensive simulations and user studies. 
Source codes for methods presented in Publications II and III, and user study data from Publication II are available at \\ \texttt{https://github.com/HIIT/knowledge-elicitation-for-linear-regression} and \\ \texttt{https://github.com/AaltoPML/knowledge-elicitation-for-precision-medicine}.




\noindent \textbf{RQ3 --} \textit{Is it enough to incorporate human knowledge directly in the data model as explained in RQ2, or could it be beneficial to account for rational knowledge updates that humans may undergo during the interaction?}

Publication IV contributes to this research question by modelling the knowledge provider, here the human user, as a rational agent that updates its knowledge about the underlying prediction task during the interaction. In particular, certain aspects of training data may be revealed (for example through visualizations) to the user during knowledge elicitation. The elicited knowledge from the user may then be, to some extent, dependent to the knowledge coming from the training data. This redundant knowledge can  result in overfitting if the user reinforces noisy patterns in the data, since the model may not account for the dependencies between training data and user feedback. We propose a user modelling methodology that assumes that the observed user feedback is an outcome of the user's rational knowledge update. The user model can then perform the reverse of the update to extract user's tacit knowledge and then update the model. The proposed user modelling idea was evaluated in a user study. 
Source code and user study data are available at \texttt{https://github.com/HIIT/human-overfitting-in-IML}.

\section{Organization of the thesis}

The organization of the thesis is as follows. Chapter 2 provides an overview of probabilistic modelling and introduces our approach of modelling the user and data as a joint probabilistic model. Chapter three investigates the design of interactions and reviews different utility functions for selecting the most informative query to be asked from the user. The fourth chapter revisits the research questions and summarizes Publications I-IV and discuses the future directions for probabilistic user modelling.



\chapter{Probabilistic modelling of data and user} \label{prob_model_data_user}
% Sami's comments 15.07.2019: I need to also explain why probabilistic modelling is good and our approach for modelling the world. 


This chapter provides a brief introduction to probabilistic modelling as the main statistical framework that is used through the thesis. After some preliminaries,  Section \ref{prob_model_data} reviews the type of linear models that are used in Publication I-V for prediction. Section \ref{prob_model_user} introduces different types of user interaction with the linear model and explains how user knowledge about the model can be incorporated as observational feedback. The computational solutions for Bayesian inference are reviewed in \ref{posteriro_inf}. %Finally, the key components for modelling observational data and user feedback as a joint probabilistic model is introduced in Section \ref{key_comp}.

\section{Preliminaries}
The core idea of probabilistic modelling is to describe all unobserved parameters and observed data as random variables from probability distributions. The unobserved parameters include the unknown quantity of interest or other parameters that affect the data or the quantity of interest. Bayesian inference provides a powerful framework to fit the described probabilistic model to observational data \cite{Gelman2013}. A core feature of Bayesian inference is that it provides probability distributions as the solution, compared to deterministic methods which provide a single outcome. This uncertainty quantification is of high interest in cases where few observational data are available or when the data acquisition scheme is controlled by the model. Both of these constrains are prominently present in the tasks investigated by this thesis.

We follow the notation of \cite{Gelman2013} and use $p(.)$ to denote a probability distribution and $p(.\mid.)$ a conditional distribution. Consider the case where there are a set of observations $\bD= \{y_1,\ldots,y_n\}$ generated from a probabilistic model with an unobserved parameter of interest $\theta$. The observational model for an observation $y$ describes the conditional density of $y$ given the parameter $\theta$ and is denoted as $y \sim p(y \mid \theta)$. It is usually assumed that the observations are conditionally independent given $\theta$, enabling us to write the model for all observations as $p(\bD \mid \theta) =  \prod_{i=1}^{n} p(y_i \mid \theta)$. The observational model is called likelihood function if perceived as a function of $\theta$ with fixed observation $y$. One of the core questions in statistical inference is to estimate the parameter of interest $\theta$ based on observations $\bD$. % and the likelihood assumption. 
Bayesian inference answers this question by computing the conditional distribution of $\theta$ given $\bD$ following the Bayes rule


\begin{equation}\label{Eq:Bayes}
p(\theta \mid \bD) = \frac{p(\bD \mid \theta)p(\theta)}{p(\bD)}.
\end{equation}  

Where $p(\theta)$ represents the prior belief about $\theta$ and $p(\bD)$ is called the marginal likelihood and acts as a normalization factor as it does not depend on $\theta$. The marginal likelihood can be computed using the marginalization rule, i.e., $p(\bD)= \int_{\theta} p(\bD, \theta)d\theta= \int_{\theta} p(\bD \mid \theta)p(\theta) d\theta$ \footnote{The integral turns to summation for discrete $\theta$.}. The conditional distribution $p(\theta \mid \bD)$ is called the posterior and it expresses the uncertainty surrounding the true value of $\theta$, after updating the prior assumptions about $\theta$ (represented by $p(\theta)$) with the knowledge coming from the observations (represented by $p(\bD \mid \theta)$).  

In many cases, we may be more interested to make a prediction about an unknown observable data point $\tilde{y}$ rather than the parameter $\theta$. Bayesian inference allows us to compute the conditional distribution of this unknown observable data given the observed data points by averaging over the posterior: 

\begin{equation}
p(\tilde{y} \mid\bD ) = \int_{\theta} p(\tilde{y}  \mid \theta)p(\theta \mid \bD)d\theta. 
\end{equation}

$p(\tilde{y} \mid \bD)$ is known as the posterior predictive distribution and represents the uncertainty about a potential new observation. An example usage of this distribution could be when we want to predict the value of a test data. Since test data is unobserved, we can use posterior predictive distribution as our best guess. However, in many applications, only a value (and not a distribution) is required as the prediction. This can be handled by using some statistics of the distribution (for example mean, mode, or median) as the prediction. Still, the quantified uncertainty in the distribution can be useful as it provides knowledge about how certain we are about our estimate. In particular, this uncertainty can help us to design more efficient interaction with a user, as will be discussed in Section \ref{interaction}.

	

\section{Modelling data for prediction} \label{prob_model_data}
%Alternative title: Prediction of high-diensional data?

Prediction is one of the core problems in statistical analysis and supervised machine learning. Given a set of $n$ input and output pairs, called training data, denoted by $\bD= \{(\bm{x}_i,y_i)\}_{i=1}^{n}$, the goal is to find a mapping from inputs to outputs. Here, $\bm{x}_i = [x_i^1,\ldots,x_i^d]\tp \in \mathbb{R}^d$ is a d-dimensional column vector representing the values of $i^{th}$ data point\footnote{We generally use bold font to refer to vectors, subscripts to index an specific item (e.g, one particular observation out of several), and superscripts to refer to dimensions of a variable.}. The dimensions are commonly called feature, covariates, or attribute. The corresponding response (or target) variable to $\bm{x}_i$ is denoted by $y_i$ which may take different forms depending on the underlying problem. In this thesis, we consider the regression tasks, meaning that we model response variables by real values, i.e., $y_i \in \mathbb{R}$. The problem is called classification in supervised learning if the response variable is restricted to a set of discrete classes represented by a categorical variable. 

\subsection{Bayesian linear regression}

A well-studied and widely practical type of regression, known as linear regression, assumes that the relationship between all inputs and their corresponding response variables is linear. This relationship can be described as 

\begin{equation*}
y_i= \sum_{j=1}^{d}x_{i}^{j} w^{j}+\epsilon_i=\bm{x}_i\tp\bw+\epsilon_i, \qquad i=1,\ldots,n, 
\end{equation*}

\noindent where $\bw \in \mathbb{R}^d$ is the regression coefficients or the model's weights and $\epsilon_i$ is the residual error between linear prediction $\bm{x}_i\tp\bw$ and the response value $y_i$. Given the labeled data $\bD$, a commonly used error function to measure the goodness of a  weight vector $\bw$, is the sum of squared of residual errors $\sum_{i=1}^n(\bm{x}_i\tp\bw- y_i)^2$. By stacking the inputs in $\bX = [x_1,\ldots,x_n]\tp \in \mathbb{R}^{n\times d}$ and outputs in $\by = [y_1,\ldots,y_n]\tp \in \mathbb{R}^n$ the error can be expressed in vector format as $(\bX\bw- \by)\tp(\bX\bw- \by)$. The frequentist approach directly finds a point estimate for $\bw$ that minimizes this error (also known as least squares solution). It is straightforward to show that $\hat{\bw} = (\bX \tp \bX)^{-1}\bX\tp \by$  would be the point estimate solution given that $(\bX \tp \bX)^{-1}$ is invertible.  

However, as mentioned, we are interested in directly quantifying the uncertainty of the solution. The probabilistic way to model this problem is to explicitly describe the model assumptions (likelihood and priors) as probability distributions. In linear regression, the residual errors $\epsilon_i$ and the weights $\bw$ are modelled as random variables and the inputs $\bm{x}_i$ as vector of values that are given. A customary assumption is to model the residual errors as independent zero-mean Gaussian random variables $\epsilon_i \sim \normalpdf(0,\sigma^2)$, where $\sigma^2$ is the variance of the Gaussian distribution which indicates the model tolerance about residual errors. It is common to also model $\sigma^2$ as another random variable with its own distribution assumption, however, for now we consider it to be a fixed hyperparameter for simplicity. The unknown quantity of interest in the linear model is the regression coefficients. To complete the Bayesian inference loop, we need to consider a prior distribution on $\bw$. There are many ways to do this depending on the underlying task. One simple prior could be to assume that coefficients are independent and each come from a zero-mean Gaussian distribution, encouraging the weights to be close to zero. This simple Bayesian linear regression can be described by

\begin{align}\label{Eq:simple_Bayesian_regression} 
\by \sim \normalpdf(\bX\bw,\sigma^2 \eye),\\
\bw \sim \normalpdf(\textbf{0},\tau^2 \eye), \nonumber
\end{align}

\noindent where $\tau^2$ is the variance of the weights and $\eye$ is the identity matrix. For simplicity we assume that $\tau^2$ is also a fixed hyperparameter. Therefore, The only unobserved parameters of this model is $\bw$. The Bayesian rule allows us to derive the posterior for $\bw$ as\footnote{We generally use the notation $\bw \sim \normalpdf(0,\tau^2 \eye)$ to denote the random variable $\bw$ and $\normalpdf(\bw\mid 0,\tau^2 \eye)$ to refer to the density function.}

\begin{equation}\label{Eq:Bayes_rule_simple_reg}
p(\bw \mid \bD) = \frac{p(\bD \mid \bw)p(\bw)}{p(\bD)} = \frac{\normalpdf(\by \mid \bX \bw,\sigma^2 \eye) \normalpdf(\bw \mid 0,\tau^2 \eye))}{p(\bD)}.
\end{equation}  

Generally, the posterior in many problems cannot be analytically derived (we will discuss this issue more in Section \ref{posteriro_inf}). For this simple model, however, an analytical solution is available. We will go through the steps as an exercise with posterior inference. Before starting, it would be useful to note that a multivariate Gaussian distribution can be expressed by its mean vector $\bm{\mu}\in \mathbb{R}^d$ and covariance matrix $\bm{\Sigma}\in \mathbb{R}^{d \times d}$ as  

\begin{align}\label{Eq:multi_Gauss}
\normalpdf(\bw \mid \bm{\mu},\bm{\Sigma}) &\propto \exp \left ((\bw - \bm{\mu})\tp\bm{\Sigma}^{-1}(\bw - \bm{\mu}) \right) \nonumber\\
&\propto \exp \left ( \bw\tp\bm{\Sigma}^{-1}\bw -  2\bw\tp\bm{\Sigma}^{-1}\bm{\mu} \right),
\end{align}

\noindent after dropping all the terms that are constant with respect to $\bw$. 

To derive the posterior, we follow Equation \ref{Eq:Bayes_rule_simple_reg} 

\begin{align} \label{Eq:lin_rel_simple_derivation}
p(\bw \mid \bD) &\propto \exp \left(\frac{1}{2\sigma^2} (\by - \bX \bw)\tp(\by - \bX \bw)\right) \exp(\frac{1}{2\tau^2}\bw\tp\bw) \nonumber\\ 
&\propto \exp \left (\sigma^{-2}(\by\tp\by - 2\bw\tp\bX\tp\by + \bw\tp\bX\tp\bX\bw)+ \tau^{-2}\bw\tp\bw \right) \nonumber\\
&\propto \exp \left ( -2\sigma^{-2}\bw\tp\bX\tp\by + \bw\tp( \sigma^{-2}\bX\tp\bX + \tau^{-2} \eye )\bw \right) %\\
%&= \exp \left ( -2\sigma^{-2}\bw\tp\bX\tp\by + \bw\tp\Sigma^{-1}\bw \right)
\end{align}    
 
\noindent where we dropped $p(\bD)$ and all the other terms which where constant with respect to $\bw$. Equation \ref{Eq:lin_rel_simple_derivation} has the same form to Equation \ref{Eq:multi_Gauss} (with respect to $\bw$) and therefore is proportional to a multivariate Gaussian distribution. This relation shows that the posterior should be multivariate Gaussian, as both equations should integrate to one, and thus its parameters can be found by matching the terms of the two equations as $\bm{\Sigma}^{-1} = ( \sigma^{-2}\bX\tp\bX + \tau^{-2} \eye ) $ and $\bm{\Sigma}^{-1}\bm{\mu} = \sigma^{-2}\bX\tp\by$. Finally, the posterior of our simple linear regression can be described as 

\begin{align}\label{Eq:lin_rel_simple_posterior}
	p(\bw \mid \bD) &= \normalpdf(\bw \mid \bm{\mu},\bm{\Sigma}), \text{where}\\
	\bm{\Sigma}^{-1} &= (\sigma^{-2}\bX\tp\bX + \tau^{-2} \eye ), \nonumber\\
	\bm{\mu} &= \bm{\Sigma}\sigma^{-2}\bX\tp\by. \nonumber
\end{align}

This simple Bayesian regression is used as the underlying data model in Publication I. It would be interesting to compare a point estimate of the posterior distribution with the frequentist solution $\hat{\bw} = (\bX \tp \bX)^{-1}\bX\tp \by$. Maximum a posteriori (MAP) is a point estimate which represents the value in the posterior that has the highest density. for multivariate Gaussian distributions, this would be equal to the mean, which after some rearrangement, can be described as $\hat{\bw}_{MAP} = (\bX\tp\bX + \frac{\sigma^{2}}{\tau^{2}} \eye )^{-1}(\bX\tp\by)$. Comparing the mean of the posterior with the frequentist solution indicates that the two estimates are very similar with the only difference that the MAP estimate has the additive term $\frac{\sigma^{2}}{\tau^{2}} \eye$ in the covariance matrix. This added term is a direct outcome of our assumptions for the likelihood and prior of the model which were not present in our simple frequentist model. This term can also be interpreted as a regularization parameter that controls the variance of weights. The designer of the model may want to consider different types of regularization or constrains in the model, which in probabilistic modelling is usually done by incorporating them in the prior distribution. Such problems may not have an analytical posterior available. We will consider two more complex models in the following subsections.



\subsubsection{Sparsity-inducing priors}

In many prediction problems, in particular those that require human intervention in a form, the number of available training data is smaller than dimensions of the problem. If not regularized properly, a model trained in this setting may overfit to the training data (achieving very low training error) while not being able to generalize properly to unobserved data (high test data error). One way to tackle this challenge is to directly regularize the model parameters so that they would not have the flexibility to overfit to the observed data. This regularization can be done by adding penalty terms, for example $l_1$ norms of the weights, to the error function in the non-Bayesian models with the general idea of pushing weights that are not useful toward zero (see for example Lasso \cite{lasso2011}). In probabilistic modelling, we can achieve the same goal by selecting sparsity-inducing priors. 

There are different priors that encourage sparsity but they can be categorized to two general groups of mixture priors, such as spike-and-slab prior \cite{spike_slab1993}, and the continuous shrinkage priors, such as horseshoe \cite{horseshoe_2017} and Laplace \cite{seeger2008bayesian} priors. The core idea of these priors is that their densities for coefficients peak at zero but at the same time have good amount of probability mass in non-zero values. In this thesis we consider the spike-and-slab prior as it introduces a binary latent variable that explicitly indicates whether a coefficient should be zero or non-zero  (relevant and not-relevant groups). This explicit explanation could be very useful as it is compatible with human opinion about inclusion/exclusion of variables in a model (we will discuss this link in detail in Section \ref{prob_model_user}).

The linear regression model with sparsity-inducing spike-and-slab prior on coefficients $\bw$ can be described as
%TODO: have the full equation in one page (now it is in two)

\begin{align}\label{Eq:ss_Bayesian_regression}
\by &\sim \normalpdf(\bX\bw,\sigma^2 \eye), \\
\sigma^{-2} &\sim \gammapdf(\alpha_{\sigma}, \beta_{\sigma}), \nonumber \\
w^j &\sim \gamma^j \normalpdf(0, \tau^2) + (1 - \gamma^j) \delta_0,  & j=1,\ldots,d, \nonumber\\
\gamma^j &\sim \bernoullipdf(\rho), & j=1,\ldots,d, \nonumber
\end{align}

\noindent where $\delta_0$ is a Dirac delta point mass at zero, and $\gamma^j$ is the binary variable that indicates whether the corresponding coefficient $w^j$ should be excluded from the model (if $\gamma^j=0$, then $w^j=0$) or should it be addressed as a normal variable (if $\gamma^j=1$, then $w^j \sim \normalpdf(0, \tau^2)$). As we are also interested in the behavior of $\gamma^j$s, we considered a Bernoulli prior distribution on all of them with the prior inclusion probability $\rho$ as a fixed hyperparameter that controls the expected number of non-zero covariates. Unlike the simple model introduced before, here we considered $\sigma^{2}$ as an unknown parameter and assumed a prior distribution for it with $\alpha_{\sigma}$ and $\beta_{\sigma}$ as fixed hyperparameters. for the three unobserved parameters $\bw$, $\bm{\gamma}$ (as a vector of all $\gamma^j$s), and $\sigma^2$ the posterior can be derived following the Bayes rule

\begin{equation}\label{Eq:Bayes_rule_ss_reg}
p(\bw, \bm{\gamma}, \sigma^2 \mid \bD) = \frac{p(\bD \mid \bw, \sigma^2)p(\bw \mid \bm{\gamma})p(\sigma^2)p(\bm{\gamma})}{p(\bD)}.
\end{equation} 

The posterior does not have an analytical solution. We will discuss different methods to compute the posterior of these types of problems in Section \ref{posteriro_inf}. The introduced spike-and-slab Sparsity-inducing model is used as the underlying data model in Publication II, III, and IV. 


\subsubsection{Detecting outliers}

In regression, there may be observations that have response values substantially different from all other data. These highly noisy observations, called outliers, can considerably affect the results if not accounted properly. A Bayesian way to handle this is to consider different variance for residual error of each observation \cite{Bayesian_ARD2007,Kangasraasio_2016_interactive}. This can be implemented by changing the observational model from $y_i\sim \normalpdf(\bm{x}_i\tp\bw,\sigma^2)$, where there was a global parameter $\sigma^2$ for the variance of all observations, to $y_i \sim \normalpdf(\bm{x}_i\tp\bw,\frac{\sigma^2}{\nu_i})$, where the new parameter $\nu_i$ controls the noise variance per observation. As $\nu_i$ is an unobserved parameter, we consider a prior distribution for it to complete the Bayesian loop:

	
\begin{align}\label{Eq:ard_Bayesian_regression}
y_i &\sim \normalpdf(\bm{x}_i\tp\bw,\frac{\sigma^2}{\nu_i}),  & i=1,\ldots,n,\\
\nu_i &\sim \gammapdf(\alpha_{\nu}, \beta_{\nu}), & i=1,\ldots,n,\nonumber \\
\sigma^{-2} &\sim \gammapdf(\alpha_{\sigma}, \beta_{\sigma}), \nonumber \\
\bw &\sim \normalpdf(\textbf{0},\tau^2 \eye), \nonumber
\end{align}

\noindent where $\alpha_{\nu}$, $\beta_{\nu}$, $\alpha_{\sigma}$, $\beta_{\sigma}$, and $\tau^2$ are fixed hyperparameters and $n$ is the number of observations. For the unobserved parameters $\bw$, $\sigma^2$, and $\bm{\nu}$ (as a vector of all $\nu_i$s), the posterior does not have an analytical solution and can be written as

\begin{equation}\label{Eq:Bayes_rule_ARD}
p(\bw, \bm{\nu}, \sigma^2 \mid \bD) = \frac{p(\bD \mid \bw, \sigma^2, \bm{\nu})p(\bw)p(\sigma^2)p(\bm{\nu})}{p(\bD)}.
\end{equation} 

Noisy observations can particularly happen if the data provider is a noisy source. For example in Publication V, we considered the setting where some of the response variables were generated from noisy physiological signals of a human user. This model was employed to handle the potential outliers in the data. 



\section{Modelling user interaction for prediction}\label{prob_model_user}

A core idea in the thesis is to model user interaction with the probabilistic model as observational feedback. These feedbacks can be tied to the model parameters via conditional distributions (feedback models). The posterior inference can then learn the unobserved parameters given data observations (as introduced in the previous section) and the feedback observations (which will be discussed in this section). The feedback models are used to incorporate the user knowledge into the regression models introduced in the previous section. The following subsections explain the proposed feedback models in Publication I-V and their relations to the probabilistic models.


\subsection{User feedback as observation about model parameters}\label{KE_models}

%This would be easy to address since the application is trivial.
Publication II and III target the case where the user has knowledge about the regression parameters and can provide feedback if queried. As mentioned, we consider high dimensional scenarios where few data points are available. An example task could be a drug response prediction given genomic features of patients \cite{drug_response_prediction}. The genomic feature size may exceed thousands of variables, but only a small number of patient data might be available and it may not be possible (or too expensive) to add new data, which make the prediction task challenging. Fortunately, experts in the field may have experience or knowledge from literature about which features, and in what ways, are relevant for this prediction task. If accounted properly, the expert knowledge can help the prediction performance. Another potential scenario is the sentiment prediction problem \cite{liu2015sentiment} when only few texts (e.g., textual reviews of items) with known sentiments (e.g., score of the review) are available. A classical representation of textual data known as bag-of-words, considers each data as a vector of distinct words where the feature value indicates the number of appearance of each word in the text\footnote{It is also common to represent textual data in dense forms such as \cite{dai2015semi}. We use bag-of-words due to its simplicity and interpretability of the features.}. Humans have intuitions about how individual words may be related to the sentiment (e.g., appearance of the word "awful" in a review may indicate low review score). Our goal is to design probabilistic models that can receive these types of expert knowledge, alongside the training data, to boost the prediction performance.  

We consider the linear regression model with sparsity-inducing spike-and-slab prior on coefficients introduced in Equation \ref{Eq:ss_Bayesian_regression} as the underlying data model. The type of feedback naturally depends on the task and availability of user knowledge.  We consider three simple and natural types of user interaction with the model: 

\begin{figure}
	\includegraphics[width=\linewidth]{Figures/Plate_diagram_KE.pdf}
	\caption{Plate notation of the prediction model (right; see Equation \ref{Eq:ss_Bayesian_regression}) and user feedback observations (left; see Equations \ref{Eq:fb_on_val_coeff}, \ref{Eq:fb_on_rel_coeff}, and \ref{Eq:fb_on_dir_coeff}). User feedback influences the data model through observations about model parameters. Circles represent variables (observed variables are shaded), and shaded squares are the fixed hyperparameters.}
	\label{fig:Plate_KE}
\end{figure}


\begin{itemize}
	\item With some noise, the user can provide feedback about the value of coefficients
	\begin{equation}\label{Eq:fb_on_val_coeff}
	f_{val}^{j} \sim \normalpdf(w^j, \omega^2),
	\end{equation}
	\noindent where $\omega^2$ models the variance of error in user feedback. Knowledge about value of coefficients is very powerful, however, only available in some specific applications (e.g., exploiting similar trained models or reported coefficient values in related literature).
	 
	\item With some probability, the user can provide feedback about whether a coefficient should be included or excluded from the model
	\begin{equation}\label{Eq:fb_on_rel_coeff}
	f_{rel}^{j} \sim \gamma^j \bernoullipdf(\pi_{rel}) + (1 - \gamma^j), \bernoullipdf(1 - \pi_{rel}).
	\end{equation}
	\noindent where $\pi_{rel}$ indicates the probability that user is correct about the feedback. This relevant $f_{rel}^{j}=1$ (or not-relevant $f_{rel}^{j}=0$) feedback is the simplest form of knowledge that a user may have about a regression task.
	 
	\item With some probability, the user can provide feedback about the direction of relevance of a coefficient, i.e., whether a feature is positively or negatively correlated with the response variable
	\begin{equation}\label{Eq:fb_on_dir_coeff}
	f_{dir}^{j} \sim I(w^j \geq 0) \bernoullipdf(\pi_{dir}) + I(w^j < 0) \bernoullipdf(1 - \pi_{dir}),
	\end{equation}
	\noindent where $\pi_{dir}$ indicates the probability that user is correct about the feedback. Feedback about positive correlation of feature $j$ is coded as $f_{dir}^{j}=1$ and negative correlation as $f_{dir}^{j}=0$.
\end{itemize}



The connection between the three mentioned feedback models with the data model (Equation \ref{Eq:ss_Bayesian_regression}) is shown as a plate diagram in Figure \ref{fig:Plate_KE}. The full posterior of the unknown parameters given data observations and the user feedback can be described as 

\begin{equation}\label{Eq:Bayes_rule_ss_reg_with_fb}
p(\bw, \bm{\gamma}, \sigma^2 \mid \bD,\bF) = \frac{p(\bD \mid \bw, \sigma^2)p(F_{val} \mid \bw)p(F_{rel} \mid \bm{\gamma})p(F_{dir} \mid \bw)p(\bw \mid \bm{\gamma})p(\sigma^2)p(\bm{\gamma})}{p(\bD,\bF)},
\end{equation} 

\noindent where $F_{val}$, $F_{rel}$, and $F_{dir}$ are the sets of collected feedback corresponding to the three considered feedback types and $\bF = (F_{val}, F_{rel}, F_{dir})$. The posterior computation is discussed in Section \ref{posteriro_inf}.

%It should be noted that there is no restriction on the amount of feedback (or the types) available for computation of the posterior. 



\subsubsection{Related works}

The proposed feedback models provide an intuitive and effortless way for the user to directly influence the prediction model without caring about the complications of the data model. Classical prior elicitation (see for example \cite{OHagan06,garthwaite2005statistical}) aims at eliciting a distribution to represent the expert's knowledge by asking about summary information such as quantiles of the parameters. This is done through iterations between the expert in the related field and statisticians who design the model. Our work goes beyond pure elicitation as it directly connects the expert to the probabilistic model, without the need to the statistician. Furthermore, By exploiting the training data and available feedback, the probabilistic model can facilitate the interaction with the expert by asking the most important questions first (interaction design will be discussed in Section \ref{interaction}).

We have considered three intuitive types of feedback models. Studies have shown that the type of domain knowledge in prediction tasks can be summarized in a small set \cite{concept_driven_CHI2019}. A different type of feedback is the case where user has knowledge about pairwise similarity of features with respect to the response variable (i.e., asking the user about which  pairs of features affect the prediction output similarly) which has been investigated in \cite{Homayun_pairwise_UMAP,Homayun_pairwise_ijcai2019}. A large body of works have studied the exclusion/inclusion of features (also known as feature selection \cite{Correia2019HumanintheLoopFS}) in different contexts, for classification  \cite{raghavan2006active,druck2009active,settles2011closing}, and regression \cite{Micallef_elicitation}. These methods are different to ours from the modelling point of view (as we consider sparse models) and also the type of interaction with the user.   

\subsection{User feedback as outcome of a cognitive process}

The feedback models proposed in the previous section consider the user as a passive data provider with some noise models. However, humans are more complicated than that. Publication IV investigates a similar knowledge elicitation task to the previous section, but aims at accounting for rational process that humans may undergo during the interaction to produce the feedback. In other words, we will define a more complex feedback model that accounts for the cognitive process of the user, with the idea that performance can be improved if we also model the thought process behind the feedback.

In many interaction scenarios, such as visual analytics or human in the loop machine learning systems, certain aspects of the training data, such as statistics or outputs of the machine learning method, may be revealed to the user  \cite{BEAMES_Endert,sacha2017you,Homayun_pairwise_UMAP,muhlbacher2013partition,Talbot2009,van2011baobabview,Kapoor2010,krause2014infuse,sarkar2015interactive,Micallef_elicitation}. This is mainly done to provide information about important characteristics of the data to improve decision making or to guide the user to facilitate the interaction. For example, in the mentioned knowledge elicitation tasks, the system may first show what it has learned about the coefficients of the linear model from the training data and then ask for user feedback about the same coefficients. Though very common, this type of interaction is prone to overfitting, as the user feedback may not be independent of the knowledge in the training data, while the machine learning methods commonly assume independence between data and user input. Studies in cognitive science have shown that humans are unintentionally biased toward the pieces of information provided for them \cite{Tversky1974,garthwaite2005statistical}. We propose a user model that accounts for such bias. In other words, the user model assumes that the user is rational \cite{gershman2015computational} and combines the information provided to her with her knowledge and then provides feedback as the outcome of such cognitive procedure. The user model can then undo the bias in the feedback by performing the inverse of the same rational update.

In particular, we consider the case where the user provides feedback about the probability of relevance of a coefficient. The belief of the model (based on data alone) about the probability of relevance of the coefficient, i.e., marginal posterior probability $p(\gamma^j \mid \bD)$, is also visualized for the user. We make the assumption that the user is rational in combining the visualized information from data with her latent knowledge. The reported feedback is then from the updated knowledge which is naturally biased as it is partially coming from the information in the training data. The model should consider this while inferring the posterior of the parameters of interest given the user feedback.
 
\begin{figure}
	\centering
	\includegraphics[width=0.80\linewidth]{Figures/Plate_diagram_OF.pdf}
	\caption{Plate notation of the prediction model (right; see Equation \ref{Eq:ss_Bayesian_regression}) and user model for feedback (left). The observed user feedback about the probability of relevance of coefficient, $p(\gamma^j \mid \bD,f^j)$, is biased as it is generated from combination of latent user knowledge about the coefficient, i.e., $p(f^j \mid \gamma^j)$, and information visualized from the data model about probability of relevance of the coefficient, i.e., $p(\gamma^j\mid \bD)$. We are interested in inferring the unbiased, latent, version of the feedback to update the parameters of interest in the data model.}
	\label{fig:Plate_OF}
\end{figure}
 
 
 
We assume that the user is rational and combines her latent knowledge about the probability of relevance of the $j^{th}$ coefficient, i.e., $p(f^{j} \mid \gamma^j=1)$, with the revealed information from the training data, i.e., $p(\gamma^j =1 \mid \bD)$, following a Bayesian update

\begin{equation}\label{Eq:Bayesian_update_biased_fb}
p(\gamma^j=1 \mid \bD, f^{j}) \propto p(f^{j}\mid \gamma^j=1)p(\gamma^j =1\mid \bD),
\end{equation}  

\noindent and provides as feedback the resulting posterior  $p(\gamma^j=1 \mid \bD, f^{j})$. The latent feedback model can be represented as $p(f^{j}\mid \gamma^j) = \pi^j \gamma^j + (1-\pi^j) (1-\gamma^j)$, with $\pi^j$ being the likelihood for latent feedback when $\gamma^j=1$. By doing the reverse of the Bayesian update in \ref{Eq:Bayesian_update_biased_fb}, we can infer $\pi^j$ as:

\begin{equation}\label{Eq:latent_knowledge_infer}
\pi^j \propto \dfrac{p(\gamma^j=1 \mid \bD, f^{j})}{p(\gamma^j =1\mid \bD)}.
\end{equation}  

We can then use the inferred user feedback $p(f^{j}\mid \gamma^j)$, instead of the observed one, to update the posterior for the parameters of interest.  Figure \ref{fig:Plate_OF} depicts a schematic of the data and user model for this problem. Publication IV shows in a simple user study that the prediction performance in a simple sentiment analysis task can be improved if the user model accounts for the rational updates that the user may undergo.

\subsubsection{Related works}

Human biases in interactive tools have been discussed in prior elicitation \cite{garthwaite2005statistical} and visual analytics \cite{bias_warning} fields. In particular, \cite{garthwaite2005statistical} reviews the common human biases from psychological literature and provides guidelines for how to reliably extract expert knowledge about uncertain quantities. In an interactive system implemented in \cite{bias_warning}, the authors proposed a framework for measurement of biases in visual analytics tools and investigated how to inform the user of potential biases. Our work is fundamentally different as we are not limiting (by following a guideline) or interrupting (by showing a warning) the interaction, but rather, acknowledge the presence of such biases and allow the user model, as part of the system, to account for those.

%Several works have investigated methods to extract more from the user feedback alone. Maybe RL works? Our work, is the first to 


\subsection{User feedback for intent modelling}\label{feedback_intent_modelling}

Intent modelling describes the task of learning the hidden intent of a user from user feedbacks. Unlike the previous mentioned scenarios where the user feedback was used as complementary information to the training data, in Publication I and V the task is to predict the user intent based on user feedback alone. An important instance of this scenario is the interactive personalized search systems where in each iteration the system recommends items and the user provides feedback regarding relevance of recommendations. The goal is not just to better predict relevance of items for the user but rather to find the most relevant item with minimal interaction. In this section, we discuss the probabilistic modelling of this task and later in Section \ref{interaction} discuss how to design the interaction so that the most relevant item can be learned as fast as possible. 

Consider the case where a user is searching for a scientific article by forming a query with keywords. The user is uncertain about the exact description of the article (e.g., the user may not know the tile), however, if the article is recommended, the user can assess its relevance. This information seeking task is usually performed in several iterations starting with an initial query, assessing the recommended results, and modifying the query with the goal of getting better results. This type of information seeking, with the user being uncertain about her information need, is known as exploratory search \cite{Marchionini2006,white2009exploratory} and covers around half of search behaviours of users \cite{Teevan_2004} (see \cite{paba_exploratory_vs_lookup} for in depth review for exploratory and standard lookup search). 

The main bottlenecks of such search systems are that (i) the amount of user feedback that can be gathered is very limited compared to the size of the information space, and (ii) the users are mostly reluctant to give more than few explicit feedback after assessing the recommended results. To tackle these challenges, Publication I, exploits the relationship between articles and their keywords and defines feedback likelihoods on both keywords and articles, providing more flexibility for the user to express her intent. Publication V investigates the modelling of noisy implicit (but effortless) feedback generated from brain activity measured through electroencephalography (EEG) and eye movements.  

The intent model is defined as a function that maps all the keywords (used to express the search intent) and articles to real values, indicating the relevance of each item for the user. As the number of user feedback is few, it is reasonable to use a simple linear model to define the relation of user feedback on keywords to the hidden intent (denoted by $\bw$):

\begin{align}\label{Eq:feedback_on_kw} 
f_{i}^{kw} \sim \normalpdf(\bm{x}_i\tp \bw, \sigma_{kw}^2), 
\end{align}

\noindent where $\sigma_{kw}^2$ models the noise of the keyword feedback. The keywords are represented in the keyword-document\footnote{We use documents to refer to articles or any other potential textual data of interest. TODO: change everything to document (instead of article)?} matrix $\bm{X} \in \mathbb{R}^{k \times d}$ where the element $(i,j)$ describes the tf-idf weighting of keyword $i$ (out of $k$ total keywords) in document $j$ (out of $d$ total documents), and $\bm{x}_i\tp$ indicates the $i^{th}$ row of the matrix. As mentioned, we are interested to also model potential user feedback on documents. We make the simplifying assumption that the expected relevance of a document can be represented as a weighted sum of the expected relevance of keywords that appear in it

\begin{align}\label{Eq:doc_key_relation} 
 \E[f_{j}^{doc}] = \sum_{i=1}^{k} p_{(i \mid j)}  \E[f_{i}^{kw}],
\end{align}

\noindent where $f_{j}^{doc}$ indicates the relevance of the $j^{th}$ document, $\E[.]$ denotes the expected value and $p_{(i \mid j)}$ is the likelihood of the $i^{th}$ keyword being present in the $j^{th}$ document. The likelihood $p_{(i \mid j)}$ is not available but can be approximated by normalizing $\bm{X}$ such that its columns sum up to one. Denoting the resulting matrix as $\hat{\bm{X}}$, writing Equation \ref{Eq:doc_key_relation} in vector format, and following  \ref{Eq:feedback_on_kw}, the feedback for relevance of documents can be described as 

\begin{align}\label{Eq:doc_key_relation_vector} 
\bm{F}^{doc} \sim \normalpdf(  \hat{\bm{X}}\tp \bm{X} \bw, \sigma_{doc}^2 \eye),
\end{align}  

\noindent where $\bm{F}^{doc}=[f_{1}^{doc},\ldots,f_{d}^{doc}]$ is the vector representation of relevance feedback for all documents, and $\sigma_{doc}^2$ models the noise of the document feedback. 

\begin{figure}
	\centering
	\includegraphics[width=0.80\linewidth]{Figures/Plate_diagram_intent_kd.pdf}
	\caption{Plate notation of the intent modelling from feedback on recommended documents and keywords. The feature transformations are not shown. The feature vector for the $i^{th}$ keyword (shown as $\bm{x}_i$) is the $i^{th}$ column of the keyword-document matrix $\bm{X}\tp$, and for the $j^{th}$ document (shown as $\bm{x}_j$) is the $j^{th}$ column of $\bm{X}\tp\hat{\bm{X}}$.}
	\label{fig:Plate_intent_kd}
\end{figure}

Given user feedback on keywords and documents the posterior of the hidden intent can be learned by assuming a Gaussian prior on the intent weights, i.e., $\bw \sim \normalpdf(\bm{0},\tau^2 \eye)$. As both likelihoods follow a Gaussian distribution, the posterior has a closed form solution and can be derived following the same derivations as the simple linear model in \ref{Eq:lin_rel_simple_posterior}. Figure \ref{fig:Plate_intent_kd} illustrates the schematic of user feedback models and its connection to the latent intent. 



\subsubsection{Implicit feedback model}

The proposed model is very simple as the noise of feedback is assumed to be known and the only unknown parameter is the intent vector $\bw$. As mentioned, we are interested to consider feedbacks from implicit sources such as neurophysiologic signals gathered from brain activities\footnote{Here we assume that the implicit feedbacks from neurophysiologic signals are already converted to a continuous relevance value (see Publication V for details).}. The implicit feedback is extremely cheap, as it requires no physical effort from the user, but at the same time extremely noisy. To exploit this noisy source of feedback along with accurate explicit feedback, we endow the model to decide on the variance of each feedback observation by using the outliers detection model proposed in \ref{Eq:ard_Bayesian_regression}. %to endow the feedback likelihood handle the inherent noise in the implicit feedback when used in combination of the explicit feedbacks.

For simplicity, let's assume that only the keyword feedback is generated from an implicit source (it is straightforward to consider an implicit feedback source for documents or to consider both explicit and implicit feedback for keywords or documents). The implicit feedback likelihood for keywords can be expressed as 

\begin{align}\label{Eq:imp_fb_on_kw} 
f_{i}^{kw} \sim \normalpdf(\bm{x}_i\tp\bw,\frac{\sigma_{kw}^2}{\nu_i}),
\end{align}  

\noindent where the parameters follow the model \ref{Eq:ard_Bayesian_regression}. The model can then infer the accuracy of each feedback, denoted by $\nu_i$, based on the observed feedbacks. The full model for the case of availability of explicit feedback on documents and implicit feedback on keywords is depicted in Figure \ref{fig:Plate_intent_imp}. The resulting posterior is analytically intractable.  

\begin{figure}
	\centering
	\includegraphics[width=0.80\linewidth]{Figures/Plate_diagram_intent_imp.pdf}
	\caption{Plate notation of the intent modelling from explicit feedback on recommended documents and noisy, implicit feedback on recommended keywords. The model is based on \ref{Eq:ard_Bayesian_regression} with the feedbacks likelihoods following \ref{Eq:imp_fb_on_kw} for keywords and \ref{Eq:doc_key_relation_vector} for documents.}
	\label{fig:Plate_intent_imp}
\end{figure}

   
\subsubsection{Related works}
Intent modelling for document search has been studied in  \cite{GlowIUI2013,ruotsalo2015interactive,Ruotsalo2018}. These works are different to ours as they only define the intent on keywords and use it as an input to a separate retrieval model (based on a standard language model) to retrieve ranked documents. We have proposed a natural document likelihood that connects the documents to the intent model which allows the model to directly rank the documents and also to gather user feedback on them. The user interface visualizes the top relevant keywords, suggested by the intent model, on a radar-like interface (borrowed from \cite{GlowIUI2013}) where the distance to center for each keyword is proportional to the predicted relevance from the intent model. The user can provide explicit feedback by dragging a keyword toward the center (indicating positive relevance) or further away from the center (indicating negative feedback). We considered clicks a document (to read the document) and bookmarks as positive feedback on the recommended documents which are presented in a list interface. 
%TODO: I have not talked about implicit feedback here. In particular: UI for JASIS is missing. Need to add more stuff in this section as it currently is a bit broken



\section{Posterior inference} \label{posteriro_inf}
Other than simple models (like the linear regression model introduced in \ref{Eq:lin_rel_simple_posterior}), the models proposed in this thesis do not have a closed-form posterior and posterior predictive distributions. For low dimensional unknown parameters, it is still practical to approximate the posterior distribution by simulation methods such as numerical computation on girds or Monte Carlo simulations (see \cite[Chapter~10]{Gelman2013} for a review). However, as mentioned, we are interested in high-dimensional problems (e.g., sentiment analysis and search with textual data, or drug response prediction with genomic data), where simple simulation methods cannot scale well due to the curse of dimensionality, i.e., the number of evaluations grows exponentially with respect to the dimension. There are two general family of methods to approach such intractable posteriors --namely Markov chain simulation and deterministic posterior approximation methods.

\subsubsection{Markov chain simulation methods}

Markov chain simulation methods are general methods to draw samples from the target posterior, i.e., $\theta^s \sim p(\theta \mid \bD)$, by starting from an initial sample in the parameter space and sequentially updating the sample toward the target posterior distribution. The sequence of dependent samples forms a chain which should have the Markov property, i.e., the updating rule to get to $\theta^{t+1}$ at time $t+1$ should only depend on the previous sample $\theta^t$, and not the whole chain. It can be shown, under some assumptions for the updating rule and the Markov chain, that by increasing the chain size toward infinity, the last sample in the chain would be a sample from the target distribution \cite[Chapter~11]{Gelman2013}. Recent advances in Markov chain simulation methods has resulted in probabilistic programming languages, such as Stan \cite{STAN} and Pyro \cite{bingham2018pyro}, that make the computation of Bayesian inference straightforward for end users. The user of such softwares needs to declare the model, and the probabilistic programming language performs the inference by providing samples from the posterior (for example see \cite{Bayesian_workflow_cog_sci_2019} for a step-by-step guides to do Bayesian modelling and inference using Stan). The posterior samples can be used to compute predictive distributions, summaries (such as expected value or other estimates), or utilities for decision making. A bottleneck of iterative simulation methods is that they can sometimes be slow. This is particularly important in the works investigated in this thesis as all of them require real-time performance with a user.

\subsubsection{Deterministic posterior approximation}

The idea of deterministic approximation methods is to approximate the target distribution, such as posterior distribution $p(\theta \mid \bD)$, with a simpler distribution $q(\theta)$ (e.g., from exponential family), i.e., $p(\theta \mid \bD) \approx q(\theta)$. The resulting approximation does not fully represent the target distribution, however, in many cases it can be efficient or accurate enough for the targeted task. There are different ways, e.g., different objective functions or assumptions about the approximated distribution, to handle the approximation. Here we briefly review the methods that have also been employed in this thesis. 

\paragraph{Variational Bayes (VB)} \cite{Blei_VB} considers $q(\theta)$ from a tractable family and refines it to be similar to the target by minimizing the Kullback–Leibler ($\KLt$) divergence between the approximation and the posterior. $\KLt$-divergence is a popular asymmetric measure of how two distributions are different from each other and for continuous $\theta$ is defined as\footnote{for discrete $\theta$ the integral turns to summation.} $\KL{q(\theta)}{p(\theta \mid \bD)} \overset{\underset{\mathrm{def}}{}}{=} \int q(\theta) \log\dfrac{q(\theta)}{p(\theta \mid \bD)} d\theta$. This objective is intractable as it requires the computation of the marginal likelihood $\log p(\bD)$. Considering $p(\theta \mid \bD)= \dfrac{p(\theta, \bD)}{p(\bD)}$, the objective can be written as $\KL{q(\theta)}{p(\theta \mid \bD)} = \log p(\bD) - \int q(\theta) \log\dfrac{p(\theta, \bD)}{q(\theta)} d\theta $. Since $\KLt$ is non-negative and $\log p(\bD)$ is constant with respect to $\theta$, the minimization of the $\KLt$-divergence would be equivalent to maximizing $L(q(\theta)) = \int q(\theta) \log\dfrac{p(\theta, \bD)}{q(\theta)} d\theta$. By appropriate choice for the model family of $q(\theta)$, the maximization of $L(q(\theta))$, also known as evidence lower bound, becomes tractable (unlike the initial objective). In particular, for the case where $\theta$ can be partitioned into disjoint group $\theta_1,\ldots,\theta_m$, by assuming factorization $q(\theta) = \prod_{j=1}^{m}q(\theta_j)$, a general expression for optimal $q(\theta_j)$, that maximizes $L(q(\theta))$, can be achieved. This approximation is known as the mean-field VB approximation which is implemented by iteratively updating the approximated factors \cite[Chapter~10]{bishop2006pattern}.  
	
Mean-field VB was used in Publication V for the posterior approximation (Equation \ref{Eq:Bayes_rule_ARD}) and partly for the approximation of the residual variance in the sparse linear model used in Publication II, III, and IV ($\sigma^2$ in Equation \ref{Eq:Bayes_rule_ss_reg_with_fb}).
	
\paragraph{Expectation propagation (EP)} \cite{minka2001expectation} aims at finding $q(\theta)$ that minimizes the Kullback–Leibler ($\KLt$) divergence between the posterior and the approximation, i.e., $\KL{p(\theta \mid \bD)}{q(\theta)}$. EP differs from VB from the objective function point of view (as the inputs of $\KLt$-divergence are reversed) and also the algorithmic solution of how it is computed. The minimization is usually intractable. The posterior distribution can be written as a product of terms $p(\theta \mid \bD) = \prod_{j} t_j(\theta)$ (for example the posterior in \ref{Eq:Bayes_rule_ss_reg_with_fb} can be viewed as product of seven terms). It it is sensible to consider the same structure for the approximated posterior $q(\theta) = \prod_{j} \tilde{t}_j(\theta)$. % \dfrac{1}{Z}, where $Z$ is a normalization factor. 
EP approximates each term $t_j(\theta)$ in the posterior by a simpler exponential family form $\tilde{t}_j(\theta)$ such that $\prod_{j} t_j(\theta) \approx \prod_{j}\tilde{t}_j(\theta)$. As the exponential family is closed under product, $q(\theta)$ also follows a simple and tractable exponential form. To optimize the terms, EP iteratively refines the parameters of $\tilde{t}_j(\theta)$ to minimize $\KL{t_j(\theta) q^{\!\!\!\backslash j}(\theta)} {\tilde{t}_j(\theta) q^{\!\!\!\backslash j}(\theta)}$, where $q^{\!\!\!\backslash j}(\theta)$ denotes the approximated posterior after removing the $j^{th}$ term, i.e.,  $q^{\!\!\!\backslash j}(\theta) \propto \frac{q(\theta)}{\tilde{t}_j(\theta)}$. This is optimized by matching the sufficient statistics of $t_j(\theta) q^{\!\!\!\backslash j}(\theta)$ with $\tilde{t}_j(\theta) q^{\!\!\!\backslash j}(\theta)$. After refining each $\tilde{t}_j(\theta)$, an updated approximation is achieved as $q(\theta)\propto q^{\!\!\!\backslash j}(\theta) \tilde{t}_j(\theta)$. This step is repeated until the convergence of all the terms.  \cite{hernandez2013generalized,Lobato2015ML,Tomi_P_thesis}
	
EP can provide good estimate to uncertainty (e.g., approximation for the posterior covariance of the weights in the linear model) that is desirable for designing interaction with a user (experimental design methods; see Section \ref{AL_and_ED}) \cite{hernandez2013generalized}. Furthermore, for sequential interaction, the inference can be sped up by only performing few iterations of parameter updates (instead of waiting for full convergence) as suggested by \cite{seeger2008bayesian}. EP was used in Publication II, III, and IV for fast approximation of the posterior of the sparse linear regression model % with sparsity-inducing spike-and-slab prior on coefficients 
with data and feedback observations (Equation \ref{Eq:Bayes_rule_ss_reg_with_fb}). The regression weights ($\bw$) were approximated by a multivariate Gaussian distribution resulting in Gaussian posterior predictive distributions, which is desirable for fast computation of the experimental design utility (see Section \ref{AL_and_ED}).  
	
%\item Normal (Laplace) approximation where the posterior is approximated with multivariate normal distribution centered at the model of the posterior (see \cite[Chapter~4]{Gelman2013} for a review), 
	
 


%\section{Key components of the joint model}\label{key_comp}




%I design probabilistic machine learning models to tie the data model (prediction model from the training data) to the user model (the model of the human) in a unified way. After doing so, we use Bayesian inference to find the posterior, i.e, distribution of the unknown parameters related to data and user, giving the training data and user interaction. The posterior inference, in most cases, does not have an analytical solution. We use different approximation methods, such as expectation propagation and variational inference, to handle the computation.



\chapter{User interaction with the probabilistic model}\label{interaction}


 
The previous chapter introduced how the user input to a high-dimensional probabilistic model can jointly be modelled with observational data and how the resulting probabilistic inference can be computed. However, the number of possible feedbacks that a human users can provide is usually limited due to the user's reluctance (e.g., in personalized system the user is usually willing to provide only a couple of feedbacks) or the time and workload constrains (as there is usually the possibility of providing feedback on thousands of items). To reduce the burden of the user and to achieve the best results faster, the interaction with the probabilistic model needs to be carefully designed. 

We consider a sequential interaction scenario where at each iteration the probabilistic model selects the next query to receive feedback from the user, and the user provides the feedback. The design of the query should be based on the history of observed feedbacks (along with training data, if available) and target of the interaction. Figure \ref{fig:infoflow} depicts a schematic of this interaction. The key components of such interactive system can be summarized as

\begin{enumerate}
	\item A data observation model $p(\bD \mid \! \theta,\phi_D)$, where the data are in the form $\bD= \{(\bm{x}_i,y_i)\}_{i=1}^{n}$, $\theta$ is the unknown parameter of interest, and $\phi_D$ are model parameters related to data model. The observational data may not be available in some applications (see Section \ref{prob_model_data}). 
	\item A user feedback model $p(f\mid \theta, \phi_F)$, where $\phi_F$ are model parameters related to the user model (see Section \ref{prob_model_user}).
	\item A prior model $p(\theta, \phi_D, \phi_F)$ for the hierarchical model description. The data and user model are connected through the shared latent parameter $\theta$.
	\item A query algorithm that facilitate gathering feedback $f$ iteratively from the user (will be discussed in this chapter).
	\item Bayesian inference for updating the model after user interaction (see Section \ref{posteriro_inf}).
\end{enumerate}

This chapter studies two general family of query algorithms for interaction with a user. Section \ref{AL_and_ED} reviews the methods that aim to design the query that maximizes the predictive performance of the probabilistic model in each iteration. Section \ref{MAP_and_BO} reviews the methods that are used to find the most relevant (rewarding) item with minimum number of queries. 


%\vspace{-0.5cm}
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[
	%node distance=2.5cm,
	%circle
	]
	\node[] at (-4.5,2) (DM) {Model $p$};
	\node[] at (-4.5,0) (D) {Data $\mathcal{D}$ (if available)};
	\node[] at (-3,1) (p1) {$p(\theta\mid\mathcal{D})$};
	\node[right=0.5cm of p1] (p2) {$p(\theta\mid\mathcal{D},f_1)$};
	\node[right=0.5cm of p2] (p3) {$p(\theta\mid\mathcal{D},f_1,f_2)$};
	\node[right=0.5cm of p3] (p4) {};
	
	\node[above right=1 and 0.28cm of p1,anchor=south] (q1) {Query 1, $f_1$};
	\node[above right=1 and 0.28cm of p2,anchor=south] (q2) {Query 2, $f_2$};
	
	\node[above right=2.5 and 0cm of p2.north,anchor=south,rectangle] (E) {User};
	
	\path[->,bend left=-25,thick] (DM) edge ([yshift=0.1cm]p1.west);
	\path[->,bend left=25,thick] (D) edge ([yshift=-0.1cm]p1.west);
	
	\path[->,thick] ([yshift=-0.1cm]p1.east) edge ([yshift=-0.1cm]p2.west);
	\path[->,thick] ([yshift=-0.1cm]p2.east) edge ([yshift=-0.1cm]p3.west);
	\path[dotted,thick] (p3) edge (p4);
	
	\path[->,bend left=-10,thick] ([yshift=0.1cm]p1.east) edge ([xshift=-0.1cm]q1.south);
	\path[->,bend left=-10,thick] ([xshift=0.1cm]q1.south) edge ([yshift=0.1cm]p2.west);
	
	\path[->,bend left=-10,thick] ([yshift=0.1cm]p2.east) edge ([xshift=-0.1cm]q2.south);
	\path[->,bend left=-10,thick] ([xshift=0.1cm]q2.south) edge ([yshift=0.1cm]p3.west);
	
	\path[<-,bend left=-20,thick] ([xshift=0.1cm]q1.north) edge ([xshift=-0.2cm]E.south);
	\path[<-,bend left=-20,thick] ([xshift=-0.4cm]E.south) edge ([xshift=-0.1cm]q1.north);
	
	\path[<-,bend left=-20,thick] ([xshift=0.1cm]q2.north) edge ([xshift=0.4cm]E.south);
	\path[<-,bend left=-20,thick] ([xshift=0.2cm]E.south) edge ([xshift=-0.1cm]q2.north);
	\end{tikzpicture}
	\caption{Sequential interaction with the user. The probabilistic model uses the history of interaction (and training data, if available) to query the next question from the user and the user provides the corresponding feedback. For brevity, the user and data related parameters, $\phi_D$ and $\phi_F$, are omitted from the posterior. The figure is adapted from Publication II.}\label{fig:infoflow}
\end{figure}



\section{Sequential experimental design}\label{AL_and_ED}

In many problems, performing new experiments is expensive. Sequential experimental design \cite{chaloner1995,seeger2008bayesian,settles2010active} (also known as active learning \cite{settles2010active}) are a family of methods that allow the underlying data model to select the next experiment that would maximally improve the model with respect to a utility measure. These methods are usually employed at the data domain, where the model asks the expert to label a new data point (e.g., identifying objects in a picture, flagging an email as spam/no-spam, assessing the sentiment of a text) with the goal to maximally improve the prediction performance of the model. In Section \ref{KE_models}, we considered the interactions at a novel level where the user could provide feedback about model parameters (such as direction of relevance of features). Here we explain how sequential experimental design for such interaction can be designed.

The aim of our work is to improve prediction on data. The prediction on an unobservable data (e.g., test data) given the observed data and also feedbacks form the user is expressed by the posterior predictive distribution of data 

\begin{equation}\label{Eq:post_pred_data_fb}
p(\tilde{y} \mid \tilde{\bm{x}}, \bD,\bF) = \int_{\theta} p(\tilde{y}  \mid \tilde{\bm{x}}, \theta)p(\theta \mid \bD, \bF)d\theta,
\end{equation}

\noindent where $\tilde{y}$ is the unobserved response variable,  $\tilde{\bm{x}}$ is the corresponding feature vector, and $\bF$ contains the gathered feedback till now. The user and data related parameters ($\phi_f$ and $\phi_D$) are omitted for brevity. The goal is to query the user about the feature, let's say $j^*$, that the corresponding feedback, i.e., $f^{j^*}$, would maximally improve this predictive distribution. The improvement can be measured by comparing the posterior predictive distribution after and before receiving the feedback using $\KLt$-divergence, i.e., $\KL{p(\tilde{y} \mid \tilde{\bm{x}}, \bD,\bF,f^{j^*})} {p(\tilde{y} \mid, \tilde{\bm{x}}, \bD,\bF)}$. This utility is known as the information gain and it measures the impact of the new feedback on the posterior predictive distribution of the data. Information gain cannot be computed as (i) the unobserved data $(\tilde{\bm{x}},\tilde{y})$ is not usually available, and (ii) the user feedback $f^{j^*}$ is observed only after querying $j^*$ from the user. Rather than computing the utility on unobserved data, we use the available training data set. Furthermore, unobserved feedback can be handled by computing the expected feedback that the user may provide after the query. The expectation would be taken with respect to the posterior predictive of user feedback (the distribution that the system believes the feedback would be generated from), i.e., $p(\tilde{f}^j \mid \bD,\bF)= \int_{\theta} p(\tilde{f}^j \mid \theta)p(\theta \mid \bD, \bF)d\theta$. The best query can then be  selected as

\begin{equation}\label{Eq:expected_info_gain}
j^* = \argmax_{j \notin \bF} \E_{p(\tilde{f}^j \mid \bD,\bF)} \left[ \sum_{i=1}^{n}  \KL{p(\tilde{y}\mid \bm{x}_i, \bD,\bF,\tilde{f}^j)} {p(\tilde{y} \mid \bm{x}_i, \bD,\bF)} \right].
\end{equation}
    
This new utility (known as expected information gain) is expensive to compute as it requires the computation of the posterior predictive distribution before and after the new feedback (which itself requires the computation of the corresponding posterior and solving the integral in Equation \ref{Eq:post_pred_data_fb}), computation of the $\KLt$-divergence, and computation of the posterior predictive of the feedback necessary for deriving the expectation. 

Publications II and III used expected information gain to sequentially extract expert's knowledge about model parameters (see Section \ref{KE_models} for a summary about the types of knowledge extracted). As mentioned, the posterior distribution of the linear regression model with sparsity-inducing spike-and-slab prior with data and feedback observations was approximated by a multivariate Gaussian distribution (see Section \ref{posteriro_inf}). It is straightforward to show that the posterior predictive distribution of data also follows a Gaussian distribution which  gives an analytical form to the $\KLt$-divergence. The posterior predictive distribution of feedback observations follow Gaussian (for feedback on value of coefficients) and Bernoulli (for feedback on relevance and direction of relevance of coefficients) distributions, which make the computation of the expectation straightforward.     
 

\section{Multi-armed bandits and Bayesian optimization}\label{MAP_and_BO}

Consider the problem of finding the argument that maximizes an objective function in a design space $\mathcal{X}$, i.e., $x^* = \argmax_{x \in \mathcal{X}} f(x)$. Now consider that the function of interest $f(x)$ is unknown and expensive to evaluate, and the only way to gain information about it is to sequentially query it, i.e., ask the function value about a point of interest, such as $x_q \in \mathcal{X}$, and observe the corresponding function value $f(x_q)$ (or in general a noisy version of it). The natural goal for this black box optimization problem could be to find $x^*$ with minimum number of queries. This problem has been extensively investigated in the multi-armed bandit \cite{bubeck2012regret} and Bayesian optimization \cite{brochu2010tutorial,BO_review} literatures. A core characteristic of these approaches is that they need to make a compromise between asking queries that would provide new information about the hidden objective function (for example in areas that have not been explored), versus exploiting the current best guess about where the maximum is and querying it. This is known as the exploration exploitation trade-off and methods in the literature propose different query strategies, known as acquisition functions, to balance it. Bayesian optimization and multi-armed bandits methods have been used in many applications such as clinical trials (finding the best treatment for a patient out of several alternatives) \cite{bubeck2012regret}, ad placement (finding the ad that would have the highest user click chance) \cite{Bandit_IR}, Automatic machine learning (searching in space of machine learning models) \cite{hoffman2014correlation}, reinforcement learning (finding the best action of an agent) \cite{brochu2010tutorial}, and personalized search systems \cite{ruotsalo2015interactive}. 

A focus application in this thesis is the personalize search systems, where the goal is to find the most relevant item for a user by minimum interaction. As the user relevance profile over items is unobserved and can only be queried through recommendations and observing user feedback, one can can map this problem to the black-box optimization problem introduced above. In particular, the problem can be formulated as finding (recommending) the item $\bm{x}_{j^*}$ that has the highest expected relevance (or equivalently highest expected feedback value). As explained in \ref{feedback_intent_modelling}, we consider the cases where the expected relevance of items have linear relationship with the unknown parameter $\bm{\theta}$\footnote{Note that we have changed the notation for the unknown weight vectors $\bm{w}$ in Section \ref{prob_model_user} to $\bm{\theta}$ for consistency.} that expresses the user intent. The optimization can then be described as: 

\begin{equation}\label{Eq:black_box_optimization}
\bm{x}^* = \argmax_{\bm{x} \in \mathcal{X}} \E [f \mid \bm{x}] = \argmax_{\bm{x} \in \mathcal{X}} \bm{x}\tp \bm{\theta}.
\end{equation}

Given a history of interaction at time $t$, $\bF_t = \{(\bm{x}_i , f_i)\}_{i=1}^{t}$, the loss of the query algorithm can be measured by the expected cumulative regret defined as:

\begin{equation}\label{Eq:regret}
\textrm{regret}_t = t \bm{x}^{*\top} \bm{\theta} - \sum_{i=1}^{t} \bm{x}_i\tp \bm{\theta}.
\end{equation} 

Note that the cumulative regret is minimized if the most relevant item is recommended to the user. The relevance profile of the user over items is determined by $\bm{\theta}$. Since we are using Bayesian statistics, we have an ongoing update of the posterior given the history of user feedback $p(\bm{\theta} \mid \bF_t)$ which can help us to better design the next query to ask from the user. % due to having an immediate expression of the uncertainty about $\bm{\theta}$. 
There are different forms of acquisition functions that exploit the model uncertainty to design the next query. Two commons ones are upper confidence bound (UCB) \cite{auer2002using,Bayes_UCB} and Thompson sampling \cite{agrawal2013thompson}, which both enjoy theoretical guarantees (for some family of problems) regarding how well they control the regret. 

Publications I and V used Thompson sampling to balance the exploration and exploitation of the recommendations. Thompson sampling follows the Bayesian idea and selects the next query according to its posterior probability of being the best query:  

\begin{equation}\label{Eq:Thompson}
\Pr(\bm{x}_{q})=\!\!\int_{\bm{\theta}}\!\!I(\argmax_{\bm{x} \in \mathcal{X}} \bm{x}\tp \bm{\theta} \!=\!\bm{x}_{q}\!\!\mid \!\bm{\theta}) p(\bm{\theta} \mid \bF_t) d\bm{\theta},
\end{equation}
 

\noindent where $\Pr(\bm{x}_{q})$ is the Thompson probability for selecting query point $\bm{x}_{q}$, and $I(.)$ is the indicator function (returns 1 if the condition in front of it holds and zero otherwise). Selection of the query at time $t+1$ according to the Thompson probabilities can be realized by the following steps:

\begin{enumerate}
	\item Draw a sample from the posterior: $ \bm{\theta}^s \sim p(\bm{\theta} \mid \bF_t)$.
	\item Find the query that has the highest expected relevance given the posterior sample: $\bm{x}_{q} = \argmax_{\bm{x} \in \mathcal{X}} \bm{x}\tp \bm{\theta}^s$.
	\item Ask the query from the user, observe user feedback, and update the posterior given the new observation: $p(\bm{\theta} \mid \bF_{t+1})$, where $ \bF_{t+1} = \bF_{t} \cup \{(\bm{x}_{q},f_q)\}$.
\end{enumerate}

In Publications I and V we considered expected feedback models for items (keywords and documents) which had a linear relation with the unknown intent parameter (see likelihoods  \ref{Eq:feedback_on_kw}, \ref{Eq:doc_key_relation_vector}, and \ref{Eq:imp_fb_on_kw} in Section \ref{feedback_intent_modelling}.). Thus, the same algorithm can be applied on them with the addition that at each iteration different query types (documents and keywords) are selected to be recommended to the user.


\chapter{Conclusions and discussion}
%Summary of the Contributions
%Applications and results OR Summary of the Publications
%Go through the papers and tasks. 
This chapter briefly summarizes the contributions of Publications I-V with emphasize on answering the research questions of the thesis. The thesis is concluded with a discussion.

\section{Interactive intent modelling from multiple feedback domains (Publications I and V)}


RQ1 was ``Can we exploit new sources of interaction as additional learning signals from human user to improve interactive intent modelling?''

Publications I and V investigated the ways to improve interactive intent modelling by considering new feedback domains. The application considered in these papers was a personalized document search problem where at each iteration the system recommends a list of documents (e.g., scientific articles) and keywords, given the history of user interaction, and the user provides feedback to them with the goal to find the most relevant document faster.

In particular, Publication I exploited the relationship between documents and keywords and proposed a joint probabilistic model that ties the user feedback on both keywords and documents (see Figure \ref{fig:Plate_intent_kd} for model description) to the latent user intent. Previous works \cite{GlowIUI2013,ruotsalo2015interactive} only defined the user intent on keywords and had a separate language model to retrieve documents. The joint probabilistic model allows to learn the user intent with fewer interaction rounds and at the same time provides a unified way to recommend keywords and documents by using Thompson sampling on the posterior of the latent intent (see Section \ref{MAP_and_BO} for details). The model was evaluated in a simulated study and a user study with 10 participants using the exploratory search system SciNet \cite{GlowIUI2013}. 

Publication V investigated the usage of noisy neurophysiologic signals gathered from brain activities (EEG signals) along with scarce explicit interactions (mouse clicks) for a the same interactive document search task. Compared to the previous work, the feedback is in the same domain of items but its generating nature is assumed to be implicit. The integration of feedbacks is challenging due to different nature of noise. To account for the inherit noise we considered a per feedback prior parameter that controls the noise of the feedback, given the feedback source. The posterior of that parameter allows the system to correct the noise and to detect outliers which are common in neurophysiologic feedback sources (see Figure \ref{fig:Plate_intent_imp} for model description). We used the same approach as Publication I to connect the feedback on documents and keywords and to recommend new items. The model was evaluated in a fully integrated information retrieval system that used the real-time generated feedback from brain activities (EEG) and  eye movements tracking (to map the brain signal to visualized items), and scarce mouse click feedback.  

The conclusion of the thesis to RQ1 is that, interactive intent modelling can be improved by adding new domains of feedback as long as the uncertainty of the feedback source and connection of the feedback to the latent intent is properly accounted for.  

\section{Expert knowledge elicitation for high-dimensional prediction (Publications II and III)}

RQ2 was ``Can expert knowledge about high dimensional data models be elicited to improve the prediction performance?''

Publications II and III studied the ways user knowledge about the parameters of a model can be encapsulated as likelihood functions and how they can sequentially be queried to improve the performance of a prediction task. Expert knowledge is particularly important in ``small $n$, large $p$'' scenarios where the number of available data points ($n$) is fewer than the dimension of the problem ($p$). An example application of such scenario that was investigated in Publication III is the drug response prediction problem given few patient profiles, where it is very costly, or some cases impossible, to add new data to the training data set but expert knowledge is available. 

Both publications contributed to the research question by providing models to add different types of expert knowledge to the prediction model (see Figure \ref{fig:Plate_KE} for the three suggested feedback types) and designing the interaction with sequential experimental design to query the most informative expert knowledge earlier (see Section \ref{AL_and_ED} for details). Both publications were evaluated by extensive simulated experiments and studies with real users/experts.

The conclusion of the thesis to RQ2 is that, even though the expert knowledge is not as powerful as new labeled data points, if connected properly to the data model, the knowledge can still significantly improve the prediction performance on small datasets. This increase in performance is noticeably fast if the queries are designed sequentially by the model so that the most informative questions are queried first. 

\section{User modelling for avoiding overfitting in knowledge elicitation (Publication IV)}

RQ3 was ``Is it enough to incorporate human knowledge directly in the data model as explained in RQ2, or could it be beneficial to account for rational knowledge updates that humans may undergo during the interaction?''

Publication IV investigates the complementary question to RQ2 of what if we acknowledge that the knowledge elicitation is being performed on a human user which comes with its own preset of biases and cognitive characteristics. In particular, we consider anchoring bias as one of the well-studied cognitive biases \cite{Tversky1974} and ask what if the knowledge elicitation system explicitly model this potential bias when gathering user feedback. The bias can particularly be harmful when extracting user knowledge after revealing certain aspects of training data, such as statistics or scatter plots. If not accounted properly, the user knowledge can be influenced by the information in the training data which may result in overfitting in the prediction model (as the user knowledge and training data are to some degree dependent). We proposed a probabilistic model that acknowledges the bias by assuming that the user updates her latent knowledge with the information in the training data that has been revealed and provides the biased feedback. The probabilistic model then accounts for the bias by performing the inverse of the knowledge update and extracting the tacit knowledge to be used in the model (see Figure \ref{fig:Plate_OF} for model description). The proposed model was evaluated on a simple user study with 49 participants and the results showed that modelling the user bias (or thinking behaviour) in knowledge elicitation improves the prediction performance.

The conclusion of the thesis to RQ2 is that interactive models can gain more from an observed user feedback if they correctly model the unobserved thinking process that the user may undergo to produce the feedback. The finding is striking as it opens a new horizon for user modelling in human-in-the-loop machine learning systems where the model acknowledges how the human user interacts and is able to condition on the thinking process to have more informative updates from an observed interaction.

%\chapter{Discussion}
\section{Discussion}

The thesis has focused on modelling the user interaction with a machine learning system as a unified probabilistic model of both the user model, i.e., model of user interaction (in the form of feedback) and intention, and the data model. The user interaction to the model has then designed as a sequential probabilistic inference problem where the most informative query from the user is selected at each iteration (see figure Figure \ref{fig:infoflow}). We believe that probabilistic user modelling would be of great importance in human-in-the-loop machine learning systems as it allows to (i) infer more information from an observed user feedback and (ii) design better interactions by exploiting the quantified uncertainty. User modelling, can provide the machine with a model of how users perceive the world, and the works in the thesis show that exploiting this knowledge can improve the interaction. Few works have investigated the benefits of such user modelling. in \cite{NIPS2016_6155} the authors ..... In \cite{peltola2019machine}, we showed that the performance of a personalized search system can be improved if the user model acknowledges that the user is exploiting a simplified model of the system they are interacting with. 

%TODO: add moer discussion. see other people's thesis




%--------------------------------END--------------------------%


 % Refer to the Journal paper 1 of this example document
%\citepub{j1} \& \cpub{j1} \& \cp{j1} \& \pageref{j1} \& \ref{j1}
% Refer to the Conference paper of this example document
%\citepub[p.~2]{c1} \& \cpub[Sec.~ 1]{c1} \&  \cp[pp.~1--2]{c1} \& \pageref{c1} \& \ref{c1} 


\renewcommand{\bibname}{References}
\bibliographystyle{plain} % Change as required
\LARGE\bibliography{references}  % remember to edit the file name




%% The following commands are for article dissertations, remove them if you write a monograph dissertation.

% Errata list, if you have errors in the publications.
%\errata

%% The first publication (journal article)
% Set the publication information.
% This command musts to be the first!
\addpublication[conference]{\underline{Pedram Daee}, Joel Pyykk\"o, Dorota G\l{}owacka, and Samuel Kaski}{Interactive Intent Modeling from Multiple Feedback Domains}{Proceedings of the 21st International Conference on Intelligent User Interfaces}{Sonoma, California, USA, 71--75}{March}{2016}{ACM.}{c1}

%\addpublication{Journal Paper Authors}{Journal Paper Title}{Journal Name}{Volume, issue, pages, and other detailed information}{Month}{Year}{Copyright Holder}{j1}
%\addpublication[conference]{Conference Paper Authors}{Conference Paper Title}{Conference Name}{Location, pages, and other detailed information}{Month}{Year}{Copyright Holder}{c1}
%\addpublication[accepted]{Journal Paper 2 Authors}{Journal Paper 2 Title}{Journal Name 2}{}{Month}{Year}{Copyright Holder}{j2}
%\addpublication[submitted]{Journal Paper 3 Authors}{Journal Paper 3 Title}{Journal Name 3}{}{Submission date}{Year}{No copyright holder at this moment}{j3}
% Add the dissertation author's contribution to that publication (the order can be interchanged with \adderrata).
\addcontribution{The author had the main responsiblity in problem formulation and modeling. The author designed and implemented the simulation experiment. Joel Pyykk\"o and the author built the system for user studies and conducted them together. The author wrote the initial draft of the manuscript, after which all co-authors joined for revisions.}
% Add the errata of the publication, remove if there are none (the order can be interchanged with \addauthorscontribution).
%\adderrata{j1 I This is wrong}
% Add the publication pdf file, the filename is the parameter (must be the last).
%TODO: uncomment the following in the final version (now commented to increase speed)
%\addpublicationpdf{Articles/IUI16.pdf}



\addpublication[journal]{\underline{Pedram Daee}$^*$, Tomi Peltola$^*$, Marta Soare$^*$, and Samuel Kaski}{Knowledge elicitation via sequential probabilistic inference for high-dimensional prediction}{Machine Learning}{106, 9-10, 1599--1620}{}{2017}{Copyright belongs to the authors.}{j1}
\addcontribution{The ideas and experiments in this article were designed jointly (the first three authors contributed equally). The author had the main responsibility in the derivation of the sequential experimental design and implementation of the experiments. Dr. Tomi Peltola derived and implemented the posterior approximation. The manuscript was written jointly.}
%TODO: uncomment the following in the final version (now commented to increase speed)
%\addpublicationpdf{Articles/ML17.pdf}



\addpublication[journal]{ Iiris Sundin$^*$, Tomi Peltola$^*$, Luana Micallef, Homayun Afrabandpey, Marta Soare, Muntasir Mamun Majumder, \underline{Pedram Daee}, Chen He, Baris Serim, Aki Havulinna, Caroline Heckman, Giulio Jacucci, Pekka Marttinen, and Samuel Kaski}{Improving genomics-based predictions for precision medicine through active elicitation of expert knowledge}{Bioinformatics}{34, 13, i395–i403}{}{2018}{Copyright belongs to the authors.}{j2}
\addcontribution{The author contributed on formulation of the sequential experimental design and implementation of a portion of the early version of the experiments. The author made comments to the manuscript in preparation.}
%TODO: uncomment the following in the final version (now commented to increase speed)
%\addpublicationpdf{Articles/Bio18.pdf}


\addpublication[conference]{\underline{Pedram Daee}$^*$, Tomi Peltola$^*$, Aki Vehtari, and Samuel Kaski}{User Modelling for Avoiding Overfitting in Interactive Knowledge Elicitation for Prediction}{Proceedings of the 23rd International Conference on Intelligent User Interfaces}{Tokyo, Japan, 305--310}{March}{2018}{ACM.}{c2}
\addcontribution{The ideas and experiments in this article were designed jointly (the first two authors contributed equally). The author designed and implemented the user study. Dr. Tomi Peltola had the main responsibility of the model formulation. The first two authors wrote the initial draft of the manuscript, after which all co-authors joined for revisions.}
%TODO: uncomment the following in the final version (now commented to increase speed)
%\addpublicationpdf{Articles/IUI18.pdf}


\addpublication[journal]{Giulio Jacucci, Oswald Barral, \underline{Pedram Daee}, Markus Wenzel, Baris Serim, Tuukka Ruotsalo, Patrik Pluchino, Jonathan Freeman, Luciano Gamberini, Samuel Kaski, Benjamin Blankertz}{Integrating Neurophysiological Relevance Feedback in Intent Modeling for Information Retrieval}{Journal of the Association for Information Science and Technology}{}{}{2019}{Copyright belongs to the authors.}{j3}
\addcontribution{The author had the main responsibility in design and implementation of the interactive intent modelling and information retrieval system, and writing of the correspnding sections. All the authors contributed to paper revisions.}
%TODO: uncomment the following in the final version (now commented to increase speed)
%\addpublicationpdf{Articles/JASIST19.pdf}

%% The fourth publication (yet another journal paper, submitted for publication, note the optional parameter)
%% Note that you are allowed to use this option only when submitting the dissertation for pre-examination!
% Set the publication information, detailed information is not printed
%\addpublication[submitted]{Salvatore Andolina$^*$, \underline{Pedram Daee}$^*$, Tung Vuong$^*$, Tuukka Ruotsalo, Khalil Klouche, Mats Sj\"oberg, Samuel Kaski, and Giulio Jacucci}{Proactive Entity Recommendation in Everyday Digital Tasks}{journal}{}{}{2019}{No copyright holder at this moment}{j4}
%\addcontribution{The ideas and experiments in this article were designed jointly (the first three authors contributed equally). The author had the main responsibility in design and implementation of the interactive intent modelling and entity recommendation system, and writing of the correspnding sections. All the authors contributed to paper revisions.}
% Add the publication pdf file, the filename is the parameter.
%\addpublicationpdf{Articles/XXX.pdf}

\end{document}
